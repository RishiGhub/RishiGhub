{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R8 Internal Lab Question Notebook.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Hbln1O8gBEih"},"source":["![alt text](https://drive.google.com/uc?export=view&id=1UXScsVx_Wni_JuDdB8LeTnM6jsPfIwkW)\n","\n","Proprietary content. © Great Learning. All Rights Reserved. Unauthorized use or distribution prohibited."]},{"cell_type":"markdown","metadata":{"id":"Q91KqmCRu64D"},"source":["# Mobile Phone Detection in an Image\n","\n","## Domain\n","Mobile Phones, Computer Vision\n","\n","## Business Context\n","The ability to process visual information using machine learning algorithms can be very useful. Electronics companies can use it to identify the presence of a mobile in an image (location), mobile brand just by looking at the image, and minor damages if there are any. The computer vision field has multiple applications and based on the available data it can be used to meet business objectives.\n","Here, we will use a simple convolutional neural network to classify images with and without mobile phones. \n"," \n","## Objective\n","\n","Given the images and label whether an image has a mobile phone or not, can you train a model that allows you to map and find the presence of mobile phones within the selected images.\n"]},{"cell_type":"markdown","metadata":{"id":"b0Qw0vEHBUvm"},"source":["### Package version\n","- tensorflow==2.3.0\n","- matplotlib==3.2.1\n","- h5py==2.10.0\n","- google==2.0.3"]},{"cell_type":"markdown","metadata":{"id":"yapdCjMwFl02"},"source":["## Table of Content\n","\n","1. Import Libraries\n","\n","2. Setting options\n","\n","3. Data loading and Data Analysis \n","\n","4. Visualize and Standardize the data\n","\n","5. Model Building\n","\n","6. Evaluate Model\n","\n","7. Conclusion and Interpretation"]},{"cell_type":"markdown","metadata":{"id":"mSnjdKmpG82x"},"source":["## 1. Import Libraries"]},{"cell_type":"markdown","metadata":{"id":"8z2Z7-OAs8QG"},"source":["Let us start by mounting the drive"]},{"cell_type":"code","metadata":{"id":"REFUdThmpz_d","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"d3ece0ec-4424-442d-9196-c17e8acc60c2"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ucnevGLoyKf_"},"source":["Let us check for the version of installed tensorflow."]},{"cell_type":"code","metadata":{"id":"W5as47YxyJVk","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"2a2324d3-1243-409f-96ab-9f4e010e3908"},"source":["# used to supress display of warnings\n","import warnings\n","\n","# os is used to provide a way of using operating system dependent functionality\n","# We use it for setting working folder\n","import os\n","\n","# Pandas is used for data manipulation and analysis\n","import pandas as pd \n","\n","# Numpy is used for large, multi-dimensional arrays and matrices, along with mathematical operators on these arrays\n","import numpy as np\n","\n","# Matplotlib is a data visualization library for 2D plots of arrays, built on NumPy arrays \n","# and designed to work with the broader SciPy stack\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from matplotlib import pyplot\n","\n","# Seaborn is based on matplotlib, which aids in drawing attractive and informative statistical graphics.\n","import seaborn as sns\n","import tensorflow \n","print(tensorflow.__version__)\n","\n","\n","from keras.utils import np_utils\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.optimizers import SGD\n","from keras.constraints import maxnorm\n","from PIL import Image\n","from PIL import ImageMath"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MRj03V7AHAYe"},"source":["## 2. Setting Options"]},{"cell_type":"code","metadata":{"id":"7I9dogoKHn6w"},"source":["# suppress display of warnings\r\n","warnings.filterwarnings('ignore')\r\n","\r\n","# display all dataframe columns\r\n","pd.options.display.max_columns = None\r\n","\r\n","# display all dataframe rows\r\n","pd.options.display.max_rows = None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ufAqcNVCHIut"},"source":["## 3. Data loading and Data Analysis "]},{"cell_type":"markdown","metadata":{"id":"LDYN63hu2s97"},"source":["### Read images and save the pixel information to an array. Also, save their corresponding label to a list ( YES-Mobile - 1, NO-Mobile - 0). Resize the images to shape (128, 128, 3)."]},{"cell_type":"code","metadata":{"id":"zWPOVY3gDOQo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FrfveOqeFtfz"},"source":["### Check shape and size of the images"]},{"cell_type":"code","metadata":{"id":"aFCElAp7FtAS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t3NWL9_NIdwK"},"source":["###  What is the percentage of images with and without mobile phone in the data"]},{"cell_type":"code","metadata":{"id":"NKy7Lw5mFVTi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JVZ2zlPNDOmi"},"source":["### Concatenate above two arrays (array having image details of with and without mobile) into one variable and check the final size of the data\r\n","### Concatenate lists having label data into one list"]},{"cell_type":"code","metadata":{"id":"88u5BB9NDs2N"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVv66DvSDvY0"},"source":["### Shuffle the above data and labels ( Data and label should be in sync)"]},{"cell_type":"code","metadata":{"id":"JC2Uu4r0EFDX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IERuYS1BHuCq"},"source":["## 4. Visualize and Standardize the data"]},{"cell_type":"markdown","metadata":{"id":"kxODV6HKykuc"},"source":["### Visualise the first 10 images in the data and print their corresponding labels."]},{"cell_type":"code","metadata":{"id":"__YELlwqE8Cl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LUvm8AMvEFaA"},"source":["### Split the data into train and test"]},{"cell_type":"code","metadata":{"id":"kKVEf3zWF0Qq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y1ZC0x0I3-jo"},"source":["### Print shape of the X train and X test data"]},{"cell_type":"code","metadata":{"id":"Dm8gmQt2FEUd"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W1Zgo_3LFSWE"},"source":["### Normalize the data by dividing by 255"]},{"cell_type":"code","metadata":{"id":"AMDN2gK0FZ22"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bogxx3cezol1"},"source":["###  One hot encode the labels for train and test data \r\n","Hint:- We need to one hot encode the labels for the model to understand the labels better. We will be using categorical cross entropy as our loss function and for this purpose we need our labels to be in one hot encoded format."]},{"cell_type":"code","metadata":{"id":"4R0pPQFBFjp1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xztigzzfITt-"},"source":["## 5. Model building"]},{"cell_type":"markdown","metadata":{"id":"UJDUoaEj1d6e"},"source":["### Define the model architecture using TensorFlow with a Conv2D layer followed by dense layers with activation as ReLu and softmax respectively. "]},{"cell_type":"code","metadata":{"id":"RhT_PLicFuDu"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DAJbHWAbF1Ko"},"source":["### Compile the above model using appropriate loss metric. Try with sgd, adam optimizer and \"accuracy\" as metrics. "]},{"cell_type":"code","metadata":{"id":"wBcO5lBmGMCW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5t90ufg46jLl"},"source":["### Fit the model on the training dataset along with it's equivalent one hot encoded labels"]},{"cell_type":"code","metadata":{"id":"1OSrPoT9GPKs"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"algw3-VGIj-N"},"source":["## 6. Evaluate the model\n"]},{"cell_type":"markdown","metadata":{"id":"PJ44TJ4gGQUC"},"source":["### Evaluate the model on test data and print loss and accuracy"]},{"cell_type":"code","metadata":{"id":"ThluFnGNGWh7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hyzKGfaKGapH"},"source":["### Predict label data of the test data and check confusion matrix"]},{"cell_type":"code","metadata":{"id":"jqlmsPhxGh-K"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C3cctwoeGwHa"},"source":["### Display test images and their predicted label for a few samples"]},{"cell_type":"code","metadata":{"id":"FvbAyNElHH_G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZruCtc4GGkVr"},"source":["### Print following plots\r\n","1. Plot training accuracy vs validation accuracy\r\n","2. Plot training loss vs validation loss"]},{"cell_type":"code","metadata":{"id":"2nf532Q_HWWM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hH63EB-xGHJq"},"source":["## 7.  Conclusion and Interpretation"]},{"cell_type":"markdown","metadata":{"id":"5ixHI0FcHIMo"},"source":["### Write your observations and findings"]},{"cell_type":"code","metadata":{"id":"0VXW4zR1GOg6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WnoWVy0GGPs5"},"source":["## 8. Further Explore"]},{"cell_type":"markdown","metadata":{"id":"NKEwRyW9JnCd"},"source":["### Try changing a few hyperparameters such as number of layers in the network or number of units in a hidden layer or try different activation functions in the hidden layers and see if you get better results than the previous network"]},{"cell_type":"code","metadata":{"id":"OFRVkBdnHbW4"},"source":[""],"execution_count":null,"outputs":[]}]}